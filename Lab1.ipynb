{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cayetano Molina, Estefanía Elvira y Priscilla González\n",
    "\n",
    "#### Laboratorio 1\n",
    "#### 16-07-24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. ¿Qué pasa si algunas acciones tienen probabilidades de cero?\n",
    "\n",
    "        En este caso, donde la probabilidad es = 0, quiere decir que lod hechos o las tareas nunca van a ser seleccionados. Por lo que se podría decir que se le quita la posibilidad de obtener recompensas bastantes valiosas o altas.\n",
    "\n",
    "2. ¿Qué pasa si la póliza es determinística?\n",
    "\n",
    "    a. π1(a) = 1 para algún a\n",
    "    \n",
    "        En este caso, siempre se eligirá la misma póliza, por lo que no se podría explorar más allá de sola una opción. Al no poderse explorar más, se perdería la chance de obtener mejores recompensas de otras acciones.\n",
    "\n",
    "3. Investigue y defina a qué se le conoce como cada uno de los siguientes términos, asegúrese de definir en qué consiste cada una de estas variaciones y cómo difieren de los k-armed bandits\n",
    "\n",
    "    a. Contextual bandits\n",
    "\n",
    "        En el contextual bandit, la mayor parte de las decisiones que se tomen o tomarán va a partir del contexto que se esté dando. En este caso, los k-armed bandits no tomarán información de más sino que se inclinarán más a elegir acciones fijas. \n",
    "\n",
    "    b. Dueling bandits\n",
    "\n",
    "        Los dueling bandits lo que hacen es que van a estar obteniendo comparaciones entre las acciones elegidas. Por lo tanto, la recompensa en este caso no es un valor cuantitativo sino que cualitativo.\n",
    "    \n",
    "    c. Combination bandits\n",
    "    \n",
    "        Como su nombre lo dice, no se trata solamente de una opción o acción, sino que de acciones combinadas en cada máquina. Esto lo que hará es aumentar la complejidad de las recompensas porque la recompensa que se obtenga se basará en la combincación de lo que se seleccione. Por lo tanto, se debe de tener un muy buen conocimiento acerca de qué acciones son buenas por separado, así como qué conjunto de opciones tamnién darán un resultado positivo. \n",
    "\n",
    "https://towardsdatascience.com/contextual-bandits-and-reinforcement-learning-6bdfeaece72a\n",
    "\n",
    "https://proceedings.mlr.press/v139/saha21a/saha21a.pdf\n",
    "\n",
    "https://domino.ai/blog/k-armed-bandit-problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
